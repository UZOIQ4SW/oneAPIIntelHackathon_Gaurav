{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EkG3DyRyoMqR"
   },
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import re\n",
    "import datetime\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearnex import patch_sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVR\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7LP3vxPZH261"
   },
   "source": [
    "Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yKewT77pEmf"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/Gaurav/Documents/Intel Hackathon/Sentiment/training_data.csv')\n",
    "test = pd.read_csv('C:/Users/Gaurav/Documents/Intel Hackathon/Sentiment/test_data.csv')\n",
    "submission = pd.read_csv('C:/Users/Gaurav/Documents/Intel Hackathon/Sentiment/sample.csv')\n",
    "test_id = test['IDLink']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9E_T1MncIEHb"
   },
   "source": [
    "Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "SPx6wg5rpdhQ",
    "outputId": "2cf28036-944e-43d9-ce3e-e9749039570b"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "v5g0ezVHJmrh",
    "outputId": "cc3bc329-63c0-481f-ddfb-371c6363f605"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "El0FyBQyJqk9",
    "outputId": "2c424591-9889-482c-bdd9-2af1893257cd"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIH3SHb1HoHu"
   },
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "3lG2TH0uG9n_",
    "outputId": "908a2bad-e667-45fb-8699-917229d8c8ab"
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "jhorvLs0HrLy",
    "outputId": "1472534d-16c8-4a31-f5c8-c4775eb20e88"
   },
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "yFKwEroWXhIO",
    "outputId": "2bca28e1-1e7d-4c43-d567-e5d7134b2a70"
   },
   "outputs": [],
   "source": [
    "train['Source'].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkGs0XdQYiNm"
   },
   "outputs": [],
   "source": [
    "train['Source'] = train['Source'].fillna('Bloomberg')\n",
    "test['Source'] = test['Source'].fillna('Bloomberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0aY5MThIbci"
   },
   "source": [
    "Text columns processing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "N0rMLhutqzT6",
    "outputId": "945f9698-40b0-456e-afbd-4505aec2a1de"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "  text_token = word_tokenize(text)\n",
    "  filtered_text = ' '.join([w.lower() for w in text_token if w.lower() not in stop and len(w) > 2])\n",
    "  filtered_text = filtered_text.replace(r\"[^a-zA-Z]+\", '')\n",
    "  text_only = re.sub(r'\\b\\d+\\b', '', filtered_text)\n",
    "  clean_text = text_only.replace(',', '').replace('.', '').replace(':', '')\n",
    "  return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yv0gu0iAYmsq"
   },
   "outputs": [],
   "source": [
    "train['Text_Title'] = train['Title'] + ' ' + train['Source'] + ' ' + train['Topic']\n",
    "test['Text_Title'] = test['Title'] + ' ' + test['Source'] + ' ' + test['Topic']\n",
    "\n",
    "train['Text_Headline'] = train['Headline'] + ' ' + train['Source'] + ' ' + train['Topic']\n",
    "test['Text_Headline'] = test['Headline'] + ' ' + test['Source'] + ' ' + test['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t0InOm6jads0",
    "outputId": "d0ff5f93-c3fe-418a-e87f-afe5f9843d33"
   },
   "outputs": [],
   "source": [
    "train['Text_Title'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5G7H85q6t_ND"
   },
   "outputs": [],
   "source": [
    "train['Text_Title'] = [clean(x) for x in train['Text_Title']]\n",
    "test['Text_Title'] = [clean(x) for x in test['Text_Title']]\n",
    "\n",
    "train['Text_Headline'] = [clean(x) for x in train['Text_Headline']]\n",
    "test['Text_Headline'] = [clean(x) for x in test['Text_Headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6XcNTv0rCswW",
    "outputId": "29189e27-3b60-44d4-c089-d2c76822844b"
   },
   "outputs": [],
   "source": [
    "train['Text_Title'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyA6ZBUDItIt"
   },
   "source": [
    "Feature extraction from text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2c_QE3z_ZpU"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "train_v_Title = vectorizer.fit_transform(train['Text_Title'])\n",
    "test_v_Title = vectorizer.transform(test['Text_Title'])\n",
    "\n",
    "vectorizer_ = TfidfVectorizer()\n",
    "\n",
    "train_v_Headline = vectorizer_.fit_transform(train['Text_Headline'])\n",
    "test_v_Headline = vectorizer_.transform(test['Text_Headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKTDHxeKntxb"
   },
   "source": [
    "SVD to reduce dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JV8OdU-EbLYm"
   },
   "source": [
    "Calculate sentiment of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RRE66bmobHt6"
   },
   "outputs": [],
   "source": [
    "train['polarity_t'] = train['Title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "test['polarity_t'] = test['Title'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "train['subjectivity_t'] = train['Title'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "test['subjectivity_t'] = test['Title'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AbVMKrtbozG"
   },
   "outputs": [],
   "source": [
    "train['polarity_h'] = train['Headline'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "test['polarity_h'] = test['Headline'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "train['subjectivity_h'] = train['Headline'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "test['subjectivity_h'] = test['Headline'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sx3xq7xbxQt"
   },
   "source": [
    "Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tw0G0avgbzig"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "train['Topic'] = encoder.fit_transform(train['Topic'])\n",
    "test['Topic'] = encoder.transform(test['Topic'])\n",
    "\n",
    "total = train['Source'].to_list() + test['Source'].to_list()\n",
    "total = encoder.fit_transform(total)\n",
    "train['Source'] = encoder.transform(train['Source'])\n",
    "test['Source'] = encoder.transform(test['Source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejUGLtC8cH19"
   },
   "source": [
    "Meta Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejrVA103oTCk"
   },
   "outputs": [],
   "source": [
    "# Get day-type(monday, tuesday) from datetime\n",
    "\n",
    "train_weekday = []\n",
    "test_weekday = []\n",
    "\n",
    "for i in train['PublishDate']:\n",
    "    train_weekday.append(datetime.datetime.strptime(i, \"%d-%m-%Y %H:%M\").strftime(\"%A\"))\n",
    "    \n",
    "for i in test['PublishDate']:\n",
    "    test_weekday.append(datetime.datetime.strptime(i, \"%d-%m-%Y %H:%M\").strftime(\"%A\"))\n",
    "\n",
    "train['weekday'] = train_weekday\n",
    "test['weekday'] = test_weekday\n",
    "\n",
    "\n",
    "# convert weekday to 0-6\n",
    "\n",
    "train['weekday'] = train['weekday'].map({'Monday': 0,\n",
    "                                        'Tuesday': 1,\n",
    "                                        'Wednesday': 2,\n",
    "                                        'Thursday': 3,\n",
    "                                        'Friday': 4,\n",
    "                                        'Saturday': 5,\n",
    "                                        'Sunday': 6})\n",
    "test['weekday'] = test['weekday'].map({'Monday': 0,\n",
    "                                        'Tuesday': 1,\n",
    "                                        'Wednesday': 2,\n",
    "                                        'Thursday': 3,\n",
    "                                        'Friday': 4,\n",
    "                                        'Saturday': 5,\n",
    "                                        'Sunday': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqdeCTDLmzWh"
   },
   "outputs": [],
   "source": [
    "# Hour from date\n",
    "\n",
    "train[\"hour\"] = train[\"PublishDate\"].apply(lambda x: x.split()[1].split(':')[0])\n",
    "test[\"hour\"] = test[\"PublishDate\"].apply(lambda x: x.split()[1].split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "o0Zukg0unpzW",
    "outputId": "bf0340dd-ff1c-46fa-8104-9c7690b247a6"
   },
   "outputs": [],
   "source": [
    "# hour distribution of SentimentTitle\n",
    "\n",
    "plt.scatter(train['hour'], train['SentimentTitle'])\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('SentimentTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "M10vjgZQnqAn",
    "outputId": "c95945a4-c49c-456b-89b2-3ec55a767cd5"
   },
   "outputs": [],
   "source": [
    "# hour distribution of SentimentHeadline\n",
    "\n",
    "plt.scatter(train['hour'], train['SentimentHeadline'])\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('SentimentHeadline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "1ybwDgiDne_F",
    "outputId": "24be12c8-3d96-4f1a-f95f-7872046ebc4f"
   },
   "outputs": [],
   "source": [
    "# weekday distribution of SentimentTitle\n",
    "\n",
    "plt.scatter(train['weekday'], train['SentimentTitle'])\n",
    "plt.xlabel('weekday')\n",
    "plt.ylabel('SentimentTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "aieMDuelnfsZ",
    "outputId": "26d37dd7-ad3d-4d64-86f0-b3266f69fc28"
   },
   "outputs": [],
   "source": [
    "# weekday distribution of SentimentHeadline\n",
    "\n",
    "plt.scatter(train['weekday'], train['SentimentHeadline'])\n",
    "plt.xlabel('weekday')\n",
    "plt.ylabel('SentimentHeadline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MKYQYq7LcKyb"
   },
   "outputs": [],
   "source": [
    "# Number of words in the Title \n",
    "train[\"num_words_t\"] = train[\"Text_Title\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words_t\"] = test[\"Text_Title\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Number of unique words in the Title \n",
    "train[\"num_unique_words_t\"] = train[\"Text_Title\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words_t\"] = test[\"Text_Title\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# Number of characters in the Title \n",
    "train[\"num_chars_t\"] = train[\"Text_Title\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars_t\"] = test[\"Text_Title\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Average length of the words in the Title \n",
    "train[\"mean_word_len_t\"] = train[\"Text_Title\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len_t\"] = test[\"Text_Title\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InxBp_3cg0ak"
   },
   "outputs": [],
   "source": [
    "# Number of words in the Headline \n",
    "train[\"num_words_h\"] = train[\"Text_Headline\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words_h\"] = test[\"Text_Headline\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Number of unique words in the Headline \n",
    "train[\"num_unique_words_h\"] = train[\"Text_Headline\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words_h\"] = test[\"Text_Headline\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# Number of characters in the Headline \n",
    "train[\"num_chars_h\"] = train[\"Text_Headline\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars_h\"] = test[\"Text_Headline\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Average length of the words in the Headline \n",
    "train[\"mean_word_len_h\"] = train[\"Text_Headline\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len_h\"] = test[\"Text_Headline\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Standard Scaler operations for Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avWWnnWPeGu1"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "cols = ['Source', 'Topic', 'Facebook', 'GooglePlus', 'LinkedIn', 'num_words_t', 'num_unique_words_t', 'num_chars_t', 'mean_word_len_t',\n",
    "        'num_words_h', 'num_unique_words_h', 'num_chars_h', 'mean_word_len_h', 'hour', 'weekday']\n",
    "\n",
    "for col in cols:\n",
    "  train[col] = scaler.fit_transform(train[col].values.reshape(-1, 1))\n",
    "  test[col] = scaler.transform(test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3vjf58SccsC"
   },
   "outputs": [],
   "source": [
    "cols_t = ['Source', 'Topic', 'Facebook', 'GooglePlus', 'LinkedIn', 'num_words_t', 'num_unique_words_t', 'num_chars_t', 'mean_word_len_t', 'polarity_t', 'subjectivity_t', 'hour', 'weekday']\n",
    "train_X1 = train[cols_t]\n",
    "test_X1 = test[cols_t]\n",
    "\n",
    "cols_h = ['Source', 'Topic', 'Facebook', 'GooglePlus', 'LinkedIn', 'num_words_h', 'num_unique_words_h', 'num_chars_h', 'mean_word_len_h', 'polarity_h', 'subjectivity_h', 'hour', 'weekday']\n",
    "train_X2 = train[cols_h]\n",
    "test_X2 = test[cols_h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "tIl9YUoSh5qD",
    "outputId": "f110cb48-6488-4c31-e4a9-261f587df7b9"
   },
   "outputs": [],
   "source": [
    "train_X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "XB3XX7-KiAWM",
    "outputId": "fd2a4a4d-01ed-4a2d-bc46-10848873a597"
   },
   "outputs": [],
   "source": [
    "train_X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "QWEA4kiliKb-",
    "outputId": "c32acfe5-2563-42fd-c3a1-f68fd13b3f88"
   },
   "outputs": [],
   "source": [
    "print(np.shape(train_X1))\n",
    "print(np.shape(test_X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PsGweej5ipnF",
    "outputId": "a35bfc60-1217-499c-efcf-dad0b0491518"
   },
   "outputs": [],
   "source": [
    "print(np.shape(train_X2))\n",
    "print(np.shape(test_X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "F8ZUxDyxiYYj",
    "outputId": "41fbf270-9da6-4883-a5c8-8470ea320e65"
   },
   "outputs": [],
   "source": [
    "print(np.shape(train_v_Title))\n",
    "print(np.shape(test_v_Title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Haa0q5c7ixK6",
    "outputId": "44b638c8-cdb0-4141-c5ac-62124393302a"
   },
   "outputs": [],
   "source": [
    "print(np.shape(train_v_Headline))\n",
    "print(np.shape(test_v_Headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_v_Headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYKCjsgAchdd"
   },
   "outputs": [],
   "source": [
    "train_X_Title = hstack([train_v_Title, csr_matrix(train_X1.values)])\n",
    "test_X_Title = hstack([test_v_Title, csr_matrix(test_X1.values)])\n",
    "y1 = train['SentimentTitle']\n",
    "\n",
    "train_X_Headline = hstack([train_v_Headline, csr_matrix(train_X2.values)])\n",
    "test_X_Headline = hstack([test_v_Headline, csr_matrix(test_X2.values)])\n",
    "y2 = train['SentimentHeadline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X_Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VBHNhB1knWrV",
    "outputId": "d0a65d44-245c-4249-c5d6-440d225231b5"
   },
   "outputs": [],
   "source": [
    "np.shape(train_X_Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yy8f0hUYNmAI"
   },
   "source": [
    "Apply Machine Learning Models without intel extension Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pysOEnMtNXpa",
    "outputId": "5d232209-cca6-4bf4-fb6f-4c1c5dd5bd35"
   },
   "outputs": [],
   "source": [
    "# LinearSVR model for SentimentTitle\n",
    "start_unopt = time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_Title, y1, test_size=0.20, random_state=42)\n",
    "\n",
    "clf1 = LinearSVR(C=0.2)\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "mae1 = mean_absolute_error(y_pred1, y_test)\n",
    "print('MAE:', 1 - mae1)\n",
    "finish_unopt = time()\n",
    "f\"Execution time without Intel(R) Extension for Scikit-learn: {(finish_unopt - start_unopt):.2f} s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kZBAbRcvN5I2",
    "outputId": "719a04c2-995f-4340-a182-8134434d85fe"
   },
   "outputs": [],
   "source": [
    "# LinearSVR model for SentimentHeadline\n",
    "start_unopt = time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_Headline, y2, test_size=0.20, random_state=42)\n",
    "\n",
    "clf2 = LinearSVR(C=0.1)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "mae2 = mean_absolute_error(y_pred2, y_test)\n",
    "print('MAE:', 1 - mae2)\n",
    "finish_unopt = time()\n",
    "f\"Execution time without Intel(R) Extension for Scikit-learn: {(finish_unopt - start_unopt):.2f} s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tPYzcJkndTDH",
    "outputId": "228f6fae-4868-4e10-c0ec-f7c59226aad8"
   },
   "outputs": [],
   "source": [
    "print('MAE:', 1 - ((0.4 * mae1) + (0.6 * mae2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Machine Learning Models with intel extension Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_opt = time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_Title, y1, test_size=0.20, random_state=42)\n",
    "\n",
    "clf1 = LinearSVR(C=0.2)\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "mae1 = mean_absolute_error(y_pred1, y_test)\n",
    "print('MAE:', 1 - mae1)\n",
    "finish_opt = time()\n",
    "f\"Execution time with Intel(R) Extension for Scikit-learn: {(finish_opt - start_opt):.2f} s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVR model for SentimentHeadline\n",
    "start_unopt = time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_Headline, y2, test_size=0.20, random_state=42)\n",
    "\n",
    "clf2 = LinearSVR(C=0.1)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "mae2 = mean_absolute_error(y_pred2, y_test)\n",
    "print('MAE:', 1 - mae2)\n",
    "finish_unopt = time()\n",
    "f\"Execution time with Intel(R) Extension for Scikit-learn: {(finish_unopt - start_unopt):.2f} s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klVR88ZMoXCL"
   },
   "source": [
    "Make predictions for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbTfoZeUdb6R"
   },
   "outputs": [],
   "source": [
    "title = clf1.predict(test_X_Title)\n",
    "headline = clf2.predict(test_X_Headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVR model for SentimentHeadline\n",
    "start_opt = time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X_Headline, y2, test_size=0.20, random_state=42)\n",
    "\n",
    "clf2 = LinearSVR(C=0.1)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "mae2 = mean_absolute_error(y_pred2, y_test)\n",
    "print('MAE:', 1 - mae2)\n",
    "finish_opt = time()\n",
    "f\"Execution time with Intel(R) Extension for Scikit-learn: {(finish_opt - start_opt):.2f} s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNgGFbhZoSEI"
   },
   "source": [
    "Save results in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEgf1XLjflp8"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['IDLink'] = test_id\n",
    "df['SentimentTitle'] = title\n",
    "df['SentimentHeadline'] = headline\n",
    "df.to_csv('C:/Users/Gaurav/Documents/Intel Hackathon/Sentiment/sample_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDnZ9rUgkc1G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ZS.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
